{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonnaVakalis/CCAI/blob/main/Tinkered_Summer_school_tutorial_citylearn_ccai_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzeHYa5GCxN7"
      },
      "outputs": [],
      "source": [
        "# MIT License\n",
        "#\n",
        "#@title Copyright (c) 2023 CCAI Community Authors { display-mode: \"form\" }\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "# CityLearn: A Tutorial on Reinforcement Learning Control for Grid-Interactive Efficient Buildings and Communities\n",
        "---\n",
        "\n",
        "Authors:\n",
        "*   [Kingsley Nweye](https://kingsleynweye.com), The University of Texas at Austin, [nweye@utexas.edu](mailto:nweye@utexas.edu)\n",
        "*   [Allen Wu](https://www.linkedin.com/in/allenjeffreywu), The University of Texas at Austin, [allen.wu@utexas.edu](mailto:allen.wu@utexas.edu)\n",
        "* [Hyun Park](), The University of Texas at Austin, [hyun_0421@utexas.edu](mailto:hyun_0421@utexas.edu)\n",
        "* [Yara Almilaify](https://www.linkedin.com/in/yara-almilaify), The University of Texas at Austin, [yara.m@utexas.edu](mailto:yara.m@utexas.edu)\n",
        "*   [Zoltan Nagy](https://www.caee.utexas.edu/people/faculty/faculty-directory/nagy), The University of Texas as Austin, [nagy@utexas.edu](mailto:nagy@utexas.edu)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "_q8SumzTFgx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for installing packages using legacy code\n",
        "!pip install setuptools==65.5.0\n",
        "\n",
        "# The environment we will be working with\n",
        "!pip install CityLearn==1.8.0\n",
        "\n",
        "# For participant interactions (buttons)\n",
        "!pip install ipywidgets==7.7.2\n",
        "\n",
        "# To generate static figures\n",
        "!pip install matplotlib==3.5.3\n",
        "!pip install seaborn==0.12.2\n",
        "\n",
        "# Provide standard RL algorithms\n",
        "# !pip install stable-baselines3==1.7.0  # This version causes an error\n",
        "!pip install wheel==0.38.4 # Install wheel first\n",
        "!pip install stable-baselines3==1.7.0\n",
        "# !pip install \"stable-baselines3[extra]>=2.0.0a4\"  # Or Replaced with this instead\n",
        "\n",
        "\n",
        "# Results submission\n",
        "!pip install requests==2.27.1\n",
        "!pip install beautifulsoup4==4.11.2\n",
        "\n",
        "# System operations\n",
        "import inspect\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "# Date and time\n",
        "from datetime import datetime\n",
        "\n",
        "# type hinting\n",
        "from typing import List, Mapping, Tuple\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "\n",
        "# User interaction\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button, FloatSlider, HBox, HTML\n",
        "from ipywidgets import IntProgress, Text, VBox\n",
        "\n",
        "# Data manipulation\n",
        "from bs4 import BeautifulSoup\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import simplejson as json\n",
        "\n",
        "# CityLearn\n",
        "from citylearn.agents.rbc import HourRBC\n",
        "from citylearn.agents.q_learning import TabularQLearning\n",
        "from citylearn.citylearn import CityLearnEnv\n",
        "from citylearn.data import DataSet\n",
        "from citylearn.reward_function import RewardFunction\n",
        "from citylearn.wrappers import NormalizedObservationWrapper\n",
        "from citylearn.wrappers import StableBaselines3Wrapper\n",
        "from citylearn.wrappers import TabularQLearningWrapper\n",
        "\n",
        "# baseline RL algorithms\n",
        "\n",
        "import stable_baselines3  # Because I modified the installed version; checking here...\n",
        "print(f\"{stable_baselines3.__version__=}\")\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "#Here we include some global settings we want applied for the remainder of the notebook:\n",
        "# set all plotted figures without margins\n",
        "plt.rcParams['axes.xmargin'] = 0\n",
        "plt.rcParams['axes.ymargin'] = 0\n"
      ],
      "metadata": {
        "id": "-eazCDbmNQqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Global Helper Functions\n",
        "\n",
        "\n",
        "The dataset is included in the CityLearn library installation which we will now read into memory. To read the dataset, all we need is the `schema.json` that defines it:"
      ],
      "metadata": {
        "id": "2gRR9HOBxOR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_schema_buildings(\n",
        "schema: dict, count: int, seed: int\n",
        ") -> Tuple[dict, List[str]]:\n",
        "    \"\"\"Randomly select number of buildings to set as active in the schema.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    schema: dict\n",
        "        CityLearn dataset mapping used to construct environment.\n",
        "    count: int\n",
        "        Number of buildings to set as active in schema.\n",
        "    seed: int\n",
        "        Seed for pseudo-random number generator\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    schema: dict\n",
        "        CityLearn dataset mapping with active buildings set.\n",
        "    buildings: List[str]\n",
        "        List of selected buildings.\n",
        "    \"\"\"\n",
        "\n",
        "    assert 1 <= count <= 15, 'count must be between 1 and 15.'\n",
        "\n",
        "    # set random seed\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # get all building names\n",
        "    buildings = list(schema['buildings'].keys())\n",
        "\n",
        "    # remove buildins 12 and 15 as they have pecularities in their data\n",
        "    # that are not relevant to this tutorial\n",
        "    buildings_to_exclude = ['Building_12', 'Building_15']\n",
        "\n",
        "    for b in buildings_to_exclude:\n",
        "        buildings.remove(b)\n",
        "\n",
        "    # randomly select specified number of buildings\n",
        "    buildings = np.random.choice(buildings, size=count, replace=False).tolist()\n",
        "\n",
        "    # reorder buildings\n",
        "    building_ids = [int(b.split('_')[-1]) for b in buildings]\n",
        "    building_ids = sorted(building_ids)\n",
        "    buildings = [f'Building_{i}' for i in building_ids]\n",
        "\n",
        "    # update schema to only included selected buildings\n",
        "    for b in schema['buildings']:\n",
        "        if b in buildings:\n",
        "            schema['buildings'][b]['include'] = True\n",
        "        else:\n",
        "            schema['buildings'][b]['include'] = False\n",
        "\n",
        "    return schema, buildings\n",
        "\n",
        "def set_schema_simulation_period(\n",
        "    schema: dict, count: int, seed: int\n",
        ") -> Tuple[dict, int, int]:\n",
        "    \"\"\"Randomly select environment simulation start and end time steps\n",
        "    that cover a specified number of days.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    schema: dict\n",
        "        CityLearn dataset mapping used to construct environment.\n",
        "    count: int\n",
        "        Number of simulation days.\n",
        "    seed: int\n",
        "        Seed for pseudo-random number generator.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    schema: dict\n",
        "        CityLearn dataset mapping with `simulation_start_time_step`\n",
        "        and `simulation_end_time_step` key-values set.\n",
        "    simulation_start_time_step: int\n",
        "        The first time step in schema time series files to\n",
        "        be read when constructing the environment.\n",
        "    simulation_end_time_step: int\n",
        "        The last time step in schema time series files to\n",
        "        be read when constructing the environment.\n",
        "    \"\"\"\n",
        "\n",
        "    assert 1 <= count <= 365, 'count must be between 1 and 365.'\n",
        "\n",
        "    # set random seed\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # use any of the files to determine the total\n",
        "    # number of available time steps\n",
        "    building_name = 'Building_14' # could be anything... FIX THIS so that it chooses one instead?\n",
        "    filename = schema['buildings'][building_name]['carbon_intensity']\n",
        "    filepath = os.path.join(root_directory, filename)\n",
        "    time_steps = pd.read_csv(filepath).shape[0]\n",
        "\n",
        "    # set candidate simulation start time steps\n",
        "    # spaced by the number of specified days\n",
        "    simulation_start_time_step_list = np.arange(0, time_steps, 24*count)  #  shouldn't the limit be time_steps - days*24 ?, (and where did 24 come from, is it number of timesteps per day? then it should be calculated...)\n",
        "\n",
        "    # randomly select a simulation start time step\n",
        "    simulation_start_time_step = np.random.choice(\n",
        "        simulation_start_time_step_list, size=1\n",
        "    )[0]\n",
        "    simulation_end_time_step = simulation_start_time_step + 24*count - 1\n",
        "\n",
        "    # update schema simulation time steps\n",
        "    schema['simulation_start_time_step'] = simulation_start_time_step\n",
        "    schema['simulation_end_time_step'] = simulation_end_time_step\n",
        "\n",
        "    return schema, simulation_start_time_step, simulation_end_time_step\n",
        "\n",
        "def set_active_observations(\n",
        "    schema: dict, active_observations: List[str]\n",
        ") -> dict:\n",
        "    \"\"\"Set the observations that will be part of the environment's\n",
        "    observation space that is provided to the control agent.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    schema: dict\n",
        "        CityLearn dataset mapping used to construct environment.\n",
        "    active_observations: List[str]\n",
        "        Names of observations to set active to be passed to control agent.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    schema: dict\n",
        "        CityLearn dataset mapping with active observations set.\n",
        "    \"\"\"\n",
        "\n",
        "    active_count = 0\n",
        "\n",
        "    for o in schema['observations']:\n",
        "        if o in active_observations:\n",
        "            schema['observations'][o]['active'] = True\n",
        "            active_count += 1\n",
        "        else:\n",
        "            schema['observations'][o]['active'] = False\n",
        "\n",
        "    valid_observations = list(schema['observations'].keys())\n",
        "    assert active_count == len(active_observations),\\\n",
        "        'the provided observations are not all valid observations.'\\\n",
        "          f' Valid observations in CityLearn are: {valid_observations}'\n",
        "\n",
        "    return schema"
      ],
      "metadata": {
        "id": "2o6iEzE_zP_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "nM0N13bijkfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 3\n",
        "print('Random seed:', RANDOM_SEED)\n",
        "\n",
        "DATASET_NAME = 'citylearn_challenge_2022_phase_all'\n",
        "schema = DataSet.get_schema(DATASET_NAME)\n",
        "\n",
        "root_directory = schema['root_directory']\n",
        "\n",
        "\n",
        "# edit next code line to change number of buildings in simulation\n",
        "BUILDING_COUNT = 3\n",
        "\n",
        " # edit next code line to change number of days in simulation\n",
        "DAY_COUNT = 7\n",
        "\n",
        "# edit next code line to change active observations in simulation\n",
        "ACTIVE_OBSERVATIONS = ['hour']\n",
        "\n",
        "schema, buildings = set_schema_buildings(schema, BUILDING_COUNT, RANDOM_SEED)\n",
        "\n",
        "schema, simulation_start_time_step, simulation_end_time_step = set_schema_simulation_period(schema, DAY_COUNT, RANDOM_SEED)\n",
        "\n",
        "schema = set_active_observations(schema, ACTIVE_OBSERVATIONS)\n",
        "\n",
        "print('Selected buildings:', buildings)\n",
        "print(\n",
        "    f'Selected {DAY_COUNT}-day period time steps:',\n",
        "    (simulation_start_time_step, simulation_end_time_step)\n",
        ")\n",
        "print(f'Active observations:', ACTIVE_OBSERVATIONS)\n",
        "\n",
        "schema['central_agent'] = True\n"
      ],
      "metadata": {
        "id": "6C6S46xmz50t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSt6h_Q-oqjK"
      },
      "source": [
        "## Initialize a CityLearn Environment\n",
        "***\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aBJ5aLZosk-"
      },
      "outputs": [],
      "source": [
        "env = CityLearnEnv(schema)\n",
        "print('Current time step:', env.time_step)\n",
        "print('environment number of time steps:', env.time_steps)\n",
        "print('environment uses central agent:', env.central_agent)\n",
        "print('Common (shared) observations amogst buildings:', env.shared_observations)\n",
        "print('Number of buildings:', len(env.buildings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9Iuu2GU52Z"
      },
      "source": [
        "### Convenience Functions to Display Simulation Results\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_kpis(env: CityLearnEnv) -> pd.DataFrame:\n",
        "    \"\"\"Returns evaluation KPIs.\n",
        "\n",
        "    Electricity consumption, cost and carbon emissions KPIs are provided\n",
        "    at the building-level and average district-level. Average daily peak,\n",
        "    ramping and (1 - load factor) KPIs are provided at the district level.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    env: CityLearnEnv\n",
        "        CityLearn environment instance.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    kpis: pd.DataFrame\n",
        "        KPI table.\n",
        "    \"\"\"\n",
        "\n",
        "    kpis = env.evaluate()\n",
        "\n",
        "    # names of KPIs to retrieve from evaluate function\n",
        "    kpi_names = [\n",
        "        'electricity_consumption', 'cost', 'carbon_emissions',\n",
        "        'average_daily_peak', 'ramping', '1 - load_factor'\n",
        "    ]\n",
        "    kpis = kpis[\n",
        "        (kpis['cost_function'].isin(kpi_names))\n",
        "    ].dropna()\n",
        "\n",
        "    # round up the values to 3 decimal places for readability\n",
        "    kpis['value'] = kpis['value'].round(3)\n",
        "\n",
        "    # rename the column that defines the KPIs\n",
        "    kpis = kpis.rename(columns={'cost_function': 'kpi'})\n",
        "\n",
        "    return kpis\n",
        ""
      ],
      "metadata": {
        "id": "aG2SsVYq0sye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_building_kpis(envs: Mapping[str, CityLearnEnv]) -> plt.Figure:\n",
        "    \"\"\"Plots electricity consumption, cost and carbon emissions\n",
        "    at the building-level for different control agents in bar charts.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    envs: Mapping[str, CityLearnEnv]\n",
        "        Mapping of user-defined control agent names to environments\n",
        "        the agents have been used to control.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig: plt.Figure\n",
        "        Figure containing plotted axes.\n",
        "    \"\"\"\n",
        "\n",
        "    kpis_list = []\n",
        "\n",
        "    for k, v in envs.items():\n",
        "        kpis = get_kpis(v)\n",
        "        kpis = kpis[kpis['level']=='building'].copy()\n",
        "        kpis['building_id'] = kpis['name'].str.split('_', expand=True)[1]\n",
        "        kpis['building_id'] = kpis['building_id'].astype(int).astype(str)\n",
        "        kpis['env_id'] = k\n",
        "        kpis_list.append(kpis)\n",
        "\n",
        "    kpis = pd.concat(kpis_list, ignore_index=True, sort=False)\n",
        "    kpi_names= kpis['kpi'].unique()\n",
        "    column_count_limit = 3\n",
        "    row_count = math.ceil(len(kpi_names)/column_count_limit)\n",
        "    column_count = min(column_count_limit, len(kpi_names))\n",
        "    building_count = len(kpis['name'].unique())\n",
        "    env_count = len(envs)\n",
        "    figsize = (3.0*column_count, 0.3*env_count*building_count*row_count)\n",
        "    fig, _ = plt.subplots(\n",
        "        row_count, column_count, figsize=figsize, sharey=True\n",
        "    )\n",
        "\n",
        "    for i, (ax, (k, k_data)) in enumerate(zip(fig.axes, kpis.groupby('kpi'))):\n",
        "        sns.barplot(x='value', y='name', data=k_data, hue='env_id', ax=ax)\n",
        "        ax.axvline(1.0, color='black', linestyle='--', label='Baseline')\n",
        "        ax.set_xlabel(None)\n",
        "        ax.set_ylabel(None)\n",
        "        ax.set_title(k)\n",
        "\n",
        "        if i == len(kpi_names) - 1:\n",
        "            ax.legend(\n",
        "                loc='upper left', bbox_to_anchor=(1.3, 1.0), framealpha=0.0\n",
        "            )\n",
        "        else:\n",
        "            ax.legend().set_visible(False)\n",
        "\n",
        "        for s in ['right','top']:\n",
        "            ax.spines[s].set_visible(False)\n",
        "\n",
        "        for p in ax.patches:\n",
        "            ax.text(\n",
        "                p.get_x() + p.get_width(),\n",
        "                p.get_y() + p.get_height()/2.0,\n",
        "                p.get_width(), ha='left', va='center'\n",
        "            )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        ""
      ],
      "metadata": {
        "id": "TVPVuSdL0xOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_district_kpis(envs: Mapping[str, CityLearnEnv]) -> plt.Figure:\n",
        "    \"\"\"Plots electricity consumption, cost, carbon emissions,\n",
        "    average daily peak, ramping and (1 - load factor) at the\n",
        "    district-level for different control agents in a bar chart.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    envs: Mapping[str, CityLearnEnv]\n",
        "        Mapping of user-defined control agent names to environments\n",
        "        the agents have been used to control.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig: plt.Figure\n",
        "        Figure containing plotted axes.\n",
        "    \"\"\"\n",
        "\n",
        "    kpis_list = []\n",
        "\n",
        "    for k, v in envs.items():\n",
        "        kpis = get_kpis(v)\n",
        "        kpis = kpis[kpis['level']=='district'].copy()\n",
        "        kpis['env_id'] = k\n",
        "        kpis_list.append(kpis)\n",
        "\n",
        "    kpis = pd.concat(kpis_list, ignore_index=True, sort=False)\n",
        "    row_count = 1\n",
        "    column_count = 1\n",
        "    env_count = len(envs)\n",
        "    kpi_count = len(kpis['kpi'].unique())\n",
        "    figsize = (6.0*column_count, 0.225*env_count*kpi_count*row_count)\n",
        "    fig, ax = plt.subplots(row_count, column_count, figsize=figsize)\n",
        "    sns.barplot(x='value', y='kpi', data=kpis, hue='env_id', ax=ax)\n",
        "    ax.axvline(1.0, color='black', linestyle='--', label='Baseline')\n",
        "    ax.set_xlabel(None)\n",
        "    ax.set_ylabel(None)\n",
        "\n",
        "    for s in ['right','top']:\n",
        "        ax.spines[s].set_visible(False)\n",
        "\n",
        "    for p in ax.patches:\n",
        "        ax.text(\n",
        "            p.get_x() + p.get_width(),\n",
        "            p.get_y() + p.get_height()/2.0,\n",
        "            p.get_width(), ha='left', va='center'\n",
        "        )\n",
        "\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1.3, 1.0), framealpha=0.0)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "wXlXXqtI04Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_building_load_profiles(envs: Mapping[str, CityLearnEnv]) -> plt.Figure:\n",
        "    \"\"\"Plots building-level net electricty consumption profile\n",
        "    for different control agents.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    envs: Mapping[str, CityLearnEnv]\n",
        "        Mapping of user-defined control agent names to environments\n",
        "        the agents have been used to control.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig: plt.Figure\n",
        "        Figure containing plotted axes.\n",
        "    \"\"\"\n",
        "\n",
        "    building_count = len(list(envs.values())[0].buildings)\n",
        "    column_count_limit = 4\n",
        "    row_count = math.ceil(building_count/column_count_limit)\n",
        "    column_count = min(column_count_limit, building_count)\n",
        "    figsize = (4.0*column_count, 1.75*row_count)\n",
        "    fig, _ = plt.subplots(row_count, column_count, figsize=figsize)\n",
        "\n",
        "    for i, ax in enumerate(fig.axes):\n",
        "        for k, v in envs.items():\n",
        "            y = v.buildings[i].net_electricity_consumption\n",
        "            x = range(len(y))\n",
        "            ax.plot(x, y, label=k)\n",
        "\n",
        "        y = v.buildings[i].net_electricity_consumption_without_storage\n",
        "        ax.plot(x, y, label='Baseline')\n",
        "        ax.set_title(v.buildings[i].name)\n",
        "        ax.set_xlabel('Time step')\n",
        "        ax.set_ylabel('kWh')\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(24))\n",
        "\n",
        "        if i == building_count - 1:\n",
        "            ax.legend(\n",
        "                loc='upper left', bbox_to_anchor=(1.0, 1.0), framealpha=0.0\n",
        "            )\n",
        "        else:\n",
        "            ax.legend().set_visible(False)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "roq__q_M0_Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_district_load_profiles(envs: Mapping[str, CityLearnEnv]) -> plt.Figure:\n",
        "    \"\"\"Plots district-level net electricty consumption profile\n",
        "    for different control agents.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    envs: Mapping[str, CityLearnEnv]\n",
        "        Mapping of user-defined control agent names to environments\n",
        "        the agents have been used to control.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig: plt.Figure\n",
        "        Figure containing plotted axes.\n",
        "    \"\"\"\n",
        "\n",
        "    figsize = (5.0, 1.5)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "\n",
        "    for k, v in envs.items():\n",
        "        y = v.net_electricity_consumption\n",
        "        x = range(len(y))\n",
        "        ax.plot(x, y, label=k)\n",
        "\n",
        "    y = v.net_electricity_consumption_without_storage\n",
        "    ax.plot(x, y, label='Baseline')\n",
        "    ax.set_xlabel('Time step')\n",
        "    ax.set_ylabel('kWh')\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(24))\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0), framealpha=0.0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "3dA40P1O1Ho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_battery_soc_profiles(envs: Mapping[str, CityLearnEnv]) -> plt.Figure:\n",
        "    \"\"\"Plots building-level battery SoC profiles fro different control agents.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    envs: Mapping[str, CityLearnEnv]\n",
        "        Mapping of user-defined control agent names to environments\n",
        "        the agents have been used to control.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig: plt.Figure\n",
        "        Figure containing plotted axes.\n",
        "    \"\"\"\n",
        "\n",
        "    building_count = len(list(envs.values())[0].buildings)\n",
        "    column_count_limit = 4\n",
        "    row_count = math.ceil(building_count/column_count_limit)\n",
        "    column_count = min(column_count_limit, building_count)\n",
        "    figsize = (4.0*column_count, 1.75*row_count)\n",
        "    fig, _ = plt.subplots(row_count, column_count, figsize=figsize)\n",
        "\n",
        "    for i, ax in enumerate(fig.axes):\n",
        "        for k, v in envs.items():\n",
        "            soc = np.array(v.buildings[i].electrical_storage.soc)\n",
        "            capacity = v.buildings[i].electrical_storage.capacity_history[0]\n",
        "            y = soc/capacity\n",
        "            x = range(len(y))\n",
        "            ax.plot(x, y, label=k)\n",
        "\n",
        "        ax.set_title(v.buildings[i].name)\n",
        "        ax.set_xlabel('Time step')\n",
        "        ax.set_ylabel('SoC')\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(24))\n",
        "\n",
        "        if i == building_count - 1:\n",
        "            ax.legend(\n",
        "                loc='upper left', bbox_to_anchor=(1.0, 1.0), framealpha=0.0\n",
        "            )\n",
        "        else:\n",
        "            ax.legend().set_visible(False)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "unYJBsZB1N-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_simulation_summary(envs: Mapping[str, CityLearnEnv]):\n",
        "    \"\"\"Plots KPIs, load and battery SoC profiles for different control agents.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    envs: Mapping[str, CityLearnEnv]\n",
        "        Mapping of user-defined control agent names to environments\n",
        "        the agents have been used to control.\n",
        "    \"\"\"\n",
        "\n",
        "    _ = plot_building_kpis(envs)\n",
        "    print('Building-level KPIs:')\n",
        "    plt.show()\n",
        "    _ = plot_building_load_profiles(envs)\n",
        "    print('Building-level load profiles:')\n",
        "    plt.show()\n",
        "    _ = plot_battery_soc_profiles(envs)\n",
        "    print('Battery SoC profiles:')\n",
        "    plt.show()\n",
        "    _ = plot_district_kpis(envs)\n",
        "    print('District-level KPIs:')\n",
        "    plt.show()\n",
        "    print('District-level load profiles:')\n",
        "    _ = plot_district_load_profiles(envs)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TyZrdT5a1UJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(**kwargs):\n",
        "    \"\"\"Returns a progress bar\"\"\"\n",
        "\n",
        "    kwargs = {\n",
        "        'value': 0,\n",
        "        'min': 0,\n",
        "        'max': 10,\n",
        "        'description': 'Simulating:',\n",
        "        'bar_style': '',\n",
        "        'style': {'bar_color': 'maroon'},\n",
        "        'orientation': 'horizontal',\n",
        "        **kwargs\n",
        "    }\n",
        "    return IntProgress(**kwargs)"
      ],
      "metadata": {
        "id": "ST3YhSkRIDLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3OX9GNVnEDt"
      },
      "outputs": [],
      "source": [
        "def plot_table(\n",
        "    ax: plt.Axes, table: np.ndarray, title: str,\n",
        "    colorbar_label: str, xlabel: str, ylabel: str\n",
        ") -> plt.Axes:\n",
        "    \"\"\"Plot 2-dimensional table on a heat map.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ax: plt.Axes\n",
        "        Figure axes\n",
        "    table: np.ndarray\n",
        "        Table array\n",
        "    title: str\n",
        "        axes title\n",
        "    colorbar_label: str\n",
        "        Colorbar name\n",
        "    xlabel: str\n",
        "        Heat map x-axis label\n",
        "    ylabel: str\n",
        "        Heat map y-axis label\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ax: plt.Axes\n",
        "        Plotted axes\n",
        "    \"\"\"\n",
        "\n",
        "    x = list(range(table.shape[0]))\n",
        "    y = list(range(table.shape[1]))\n",
        "    z = table.T\n",
        "    pcm = ax.pcolormesh(\n",
        "        x, y, z, shading='nearest', cmap=cmap,\n",
        "        edgecolors='black', linewidth=0.0\n",
        "    )\n",
        "    _ = fig.colorbar(\n",
        "        pcm, ax=ax, orientation='horizontal',\n",
        "        label=colorbar_label, fraction=0.025, pad=0.08\n",
        "    )\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.set_title(title)\n",
        "\n",
        "    return ax\n",
        "\n",
        "cmap = 'coolwarm'\n",
        "figsize = (12, 8)\n",
        "fig, axs = plt.subplots(1, 3, figsize=figsize, sharey=True)\n",
        "axs[0] = plot_table(\n",
        "    axs[0], tql_model.q[0], 'Q-Table',\n",
        "    'Q-Value', 'State (Hour)', 'Action Index'\n",
        ")\n",
        "axs[1] = plot_table(\n",
        "    axs[1], tql_model.q_exploration[0], 'Q-Table Exploration',\n",
        "    'Count','State (Hour)', None\n",
        ")\n",
        "axs[2] = plot_table(\n",
        "    axs[2], tql_model.q_exploitation[0], 'Q-Table Exploitation',\n",
        "    'Count', 'State (Hour)', None\n",
        ")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For SAC\n",
        "\n",
        "def plot_actions(actions_list: List[List[float]], title: str) -> plt.Figure:\n",
        "    \"\"\"Plots action time series for different buildings\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    actions_list: List[List[float]]\n",
        "        List of actions where each element with index, i,\n",
        "        in list is a list of the actions for different buildings\n",
        "        taken at time step i.\n",
        "    title: str\n",
        "        Plot axes title\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fig: plt.Figure\n",
        "        Figure with plotted axes\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 1))\n",
        "    columns = [b.name for b in sac_env.buildings]\n",
        "    plot_data = pd.DataFrame(actions_list, columns=columns)\n",
        "    x = list(range(plot_data.shape[0]))\n",
        "\n",
        "    for c in plot_data.columns:\n",
        "        y = plot_data[c].tolist()\n",
        "        ax.plot(x, y, label=c)\n",
        "\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0), framealpha=0.0)\n",
        "    ax.set_xlabel('Time step')\n",
        "    ax.set_ylabel(r'$\\frac{kWh}{kWh_{capacity}}$')\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(24))\n",
        "    ax.set_title(title)\n",
        "\n",
        "    return fig\n",
        ""
      ],
      "metadata": {
        "id": "tLIKfCXO5xiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Soft Actor Critic"
      ],
      "metadata": {
        "id": "a0_B66VUGJoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sac_env = CityLearnEnv(schema)\n",
        "sac_env = NormalizedObservationWrapper(sac_env) # CityLearn wrapper s.t. all observations that are served to the agent are min-max normalized between [0, 1] and cyclical observations e.g. hour, are encoded using the sine and cosine transformation.\n",
        "sac_env = StableBaselines3Wrapper(sac_env) # wrapper that ensures observations, actions and rewards are served in manner that is compatible with Stable Baselines3 interface\n",
        "sac_model = SAC(policy='MlpPolicy', env=sac_env, seed=RANDOM_SEED)"
      ],
      "metadata": {
        "id": "n9A8-38t390y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to track the progress of learning, we will use a loader as we have done before. Stable Baselines3 makes use of callbacks to help with performing user-defined actions and procedures during learning. However, you do not need to know the specifics of the code below beyond being aware that it is used to update the loader value and store aggregated rewards at each time step."
      ],
      "metadata": {
        "id": "3HQNnT8O4Qmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCallback(BaseCallback):\n",
        "    def __init__(self, env: CityLearnEnv, loader: IntProgress):\n",
        "        r\"\"\"Initialize CustomCallback.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env: Mapping[str, CityLearnEnv]\n",
        "            CityLearn environment instance.\n",
        "        loader: IntProgress\n",
        "            Progress bar.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(verbose=0)\n",
        "        self.loader = loader\n",
        "        self.env = env\n",
        "        self.reward_history = [0]\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        r\"\"\"Called each time the env step function is called.\"\"\"\n",
        "\n",
        "        if self.env.time_step == 0:\n",
        "            self.reward_history.append(0)\n",
        "\n",
        "        else:\n",
        "            self.reward_history[-1] += sum(self.env.rewards[-1])\n",
        "\n",
        "        self.loader.value += 1\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "LtnL5S394TJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a Custom Reward Function\n"
      ],
      "metadata": {
        "id": "dt77XG7I6Fd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomReward(RewardFunction):\n",
        "    def __init__(self, env: CityLearnEnv):\n",
        "        r\"\"\"Initialize CustomReward.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env: Mapping[str, CityLearnEnv]\n",
        "            CityLearn environment instance.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(env)\n",
        "\n",
        "    def calculate(self) -> List[float]:\n",
        "        r\"\"\"Returns reward for most recent action.\n",
        "\n",
        "        The reward is designed to minimize electricity cost.\n",
        "        It is calculated for each building, i and summed to provide the agent\n",
        "        with a reward that is representative of all n buildings.\n",
        "        It encourages net-zero energy use by penalizing grid load satisfaction\n",
        "        when there is energy in the battery as well as penalizing\n",
        "        net export when the battery is not fully charged through the penalty\n",
        "        term. There is neither penalty nor reward when the battery\n",
        "        is fully charged during net export to the grid. Whereas, when the\n",
        "        battery is charged to capacity and there is net import from the\n",
        "        grid the penalty is maximized.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        reward: List[float]\n",
        "            Reward for transition to current timestep.\n",
        "        \"\"\"\n",
        "\n",
        "        reward_list = []\n",
        "\n",
        "        for b in self.env.buildings:\n",
        "            cost = b.net_electricity_consumption_cost[-1]\n",
        "            battery_capacity = b.electrical_storage.capacity_history[0]\n",
        "            battery_soc = b.electrical_storage.soc[-1]/battery_capacity\n",
        "            penalty = -(1.0 + np.sign(cost)*battery_soc)\n",
        "            reward = penalty*abs(cost)\n",
        "            reward_list.append(reward)\n",
        "\n",
        "        reward = [sum(reward_list)]\n",
        "\n",
        "        return reward"
      ],
      "metadata": {
        "id": "oPK08TkI6Jsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Environment, Agent and Reward Function\n",
        ""
      ],
      "metadata": {
        "id": "nunxV4ev6wWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CUSTOMIZE **YOUR** ENVIRONMENT --------------------\n",
        "# Include other observations if needed.\n",
        "# See https://www.citylearn.net/overview/observations.html\n",
        "# for table of observations that you can include\n",
        "# NOTE: More active observations could mean longer trainer time.\n",
        "your_active_observations = [\n",
        "    'hour',\n",
        "    'day_type'\n",
        "]\n",
        "\n",
        "# ------------------ SET **YOUR** AGENT HYPERPARAMETERS ------------------\n",
        "# try out different hyperparameter value combinations to see\n",
        "# which one provides you with the best KPIs. See\n",
        "# https://github.com/yosider/ml-agents-1/blob/master/docs/Training-SAC.md#training-with-soft-actor-critic\n",
        "# for a guide on how to select hyperparameter values.\n",
        "your_agent_kwargs = {\n",
        "    'learning_rate': 0.001,\n",
        "    'buffer_size': 1000000,\n",
        "    'learning_starts': 100,\n",
        "    'batch_size': 256,\n",
        "    'tau': 0.005,\n",
        "    'gamma': 0.99,\n",
        "    'train_freq': 1,\n",
        "}\n",
        "\n",
        "# --------------- SET **YOUR** NUMBER OF TRAINING EPISODES ---------------\n",
        "your_episodes = sac_episodes\n",
        "\n",
        "# --------------- DEFINE **YOUR** CUSTOM REWARD FUNCTION -----------------\n",
        "class YourCustomReward(CustomReward):\n",
        "    def __init__(self, env: CityLearnEnv):\n",
        "        r\"\"\"Initialize CustomReward.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env: Mapping[str, CityLearnEnv]\n",
        "            CityLearn environment instance.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(env)\n",
        "\n",
        "    def calculate(self) -> List[float]:\n",
        "        r\"\"\"Returns reward for most recent action.\n",
        "\n",
        "        <Provide a description for your custom reward>.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        reward: List[float]\n",
        "            Reward for transition to current timestep.\n",
        "        \"\"\"\n",
        "\n",
        "        # comment the next line of code and define your custom reward otherwise,\n",
        "        # leave as is to use the previously defined custom reward function.\n",
        "        #reward = super().calculate()\n",
        "        reward_list = []\n",
        "\n",
        "        for b in self.env.buildings:\n",
        "            cost = b.net_electricity_consumption_cost[-1]\n",
        "            battery_capacity = b.electrical_storage.capacity_history[0]\n",
        "            battery_soc = b.electrical_storage.soc[-1]/battery_capacity\n",
        "            penalty = -(1.0 + np.sign(cost)*battery_soc)\n",
        "            reward = penalty*abs(cost)\n",
        "            reward_list.append(reward)\n",
        "\n",
        "        reward = [sum(reward_list)]\n",
        "\n",
        "\n",
        "        return reward"
      ],
      "metadata": {
        "id": "zjkvrnpS6yhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "Here we define one function that performs all the procedures we took to train the SAC agent from selecting buildings, simulation period and active observations to initializing and wrapping the environment, initializing the agent, training it a nd reporting it's results:"
      ],
      "metadata": {
        "id": "M212veso630o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_your_custom_sac(\n",
        "    agent_kwargs: dict, episodes: int, reward_function: RewardFunction,\n",
        "    building_count: int, day_count: int, active_observations: List[str],\n",
        "    random_seed: int, reference_envs: Mapping[str, CityLearnEnv] = None,\n",
        "    show_figures: bool = None\n",
        ") -> dict:\n",
        "    \"\"\"Trains a custom soft-actor critic (SAC) agent on a custom environment.\n",
        "\n",
        "    Trains an SAC agent using a custom environment and agent hyperparamter\n",
        "    setup and plots the key performance indicators (KPIs), actions and\n",
        "    rewards from training and evaluating the agent.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    agent_kwargs: dict\n",
        "        Defines the hyperparameters used to initialize the SAC agent.\n",
        "    episodes: int\n",
        "        Number of episodes to train the agent for.\n",
        "    reward_function: RewardFunction\n",
        "        A base or custom reward function class.\n",
        "    building_count: int\n",
        "        Number of buildings to set as active in schema.\n",
        "    day_count: int\n",
        "        Number of simulation days.\n",
        "    active_observations: List[str]\n",
        "        Names of observations to set active to be passed to control agent.\n",
        "    random_seed: int\n",
        "        Seed for pseudo-random number generator.\n",
        "    reference_envs: Mapping[str, CityLearnEnv], default: None\n",
        "        Mapping of user-defined control agent names to environments\n",
        "        the agents have been used to control.\n",
        "    show_figures: bool, default: False\n",
        "        Indicate if summary figures should be plotted at the end of\n",
        "        evaluation.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    result: dict\n",
        "        Results from training the agent as well as some input variables\n",
        "        for reference including the following value keys:\n",
        "\n",
        "            * random_seed: int\n",
        "            * env: CityLearnEnv\n",
        "            * model: SAC\n",
        "            * actions: List[float]\n",
        "            * rewards: List[float]\n",
        "            * agent_kwargs: dict\n",
        "            * episodes: int\n",
        "            * reward_function: RewardFunction\n",
        "            * buildings: List[str]\n",
        "            * simulation_start_time_step: int\n",
        "            * simulation_end_time_step: int\n",
        "            * active_observations: List[str]\n",
        "            * train_start_timestamp: datetime\n",
        "            * train_end_timestamp: datetime\n",
        "    \"\"\"\n",
        "\n",
        "    # get schema\n",
        "    schema = DataSet.get_schema('citylearn_challenge_2022_phase_all')\n",
        "\n",
        "    # select buildings\n",
        "    schema, buildings = set_schema_buildings(\n",
        "        schema, building_count, random_seed\n",
        "    )\n",
        "    print('Selected buildings:', buildings)\n",
        "\n",
        "    # select days\n",
        "    schema, simulation_start_time_step, simulation_end_time_step =\\\n",
        "        set_schema_simulation_period(schema, day_count, random_seed)\n",
        "    print(\n",
        "        f'Selected {day_count}-day period time steps:',\n",
        "        (simulation_start_time_step, simulation_end_time_step)\n",
        "    )\n",
        "\n",
        "    # set active observations\n",
        "    schema = set_active_observations(schema, active_observations)\n",
        "    print(f'Active observations:', active_observations)\n",
        "\n",
        "    # initialize environment\n",
        "    env = CityLearnEnv(schema, central_agent=True)\n",
        "\n",
        "    # set reward function\n",
        "    env.reward_function = reward_function(env=env)\n",
        "\n",
        "    # wrap environment\n",
        "    env = NormalizedObservationWrapper(env)\n",
        "    env = StableBaselines3Wrapper(env)\n",
        "\n",
        "    # initialize agent\n",
        "    model = SAC('MlpPolicy', env, **agent_kwargs, seed=random_seed)\n",
        "\n",
        "    # initialize loader\n",
        "    total_timesteps = episodes*(env.time_steps - 1)\n",
        "    print('Number of episodes to train:', episodes)\n",
        "    loader = get_loader(max=total_timesteps)\n",
        "    display(loader)\n",
        "\n",
        "    # initialize callback\n",
        "    callback = CustomCallback(env=env, loader=loader)\n",
        "\n",
        "    # train agent\n",
        "    train_start_timestamp = datetime.utcnow()\n",
        "    model = model.learn(total_timesteps=total_timesteps, callback=callback)\n",
        "    train_end_timestamp = datetime.utcnow()\n",
        "\n",
        "    # evaluate agent\n",
        "    observations = env.reset()\n",
        "    actions_list = []\n",
        "\n",
        "    while not env.done:\n",
        "        actions, _ = model.predict(observations, deterministic=True)\n",
        "        observations, _, _, _ = env.step(actions)\n",
        "        actions_list.append(actions)\n",
        "\n",
        "    # get rewards\n",
        "    rewards = callback.reward_history[:episodes]\n",
        "\n",
        "    # plot summary and compare with other control results\n",
        "    if show_figures is not None and show_figures:\n",
        "        env_id = 'Your-SAC'\n",
        "\n",
        "        if reference_envs is None:\n",
        "            reference_envs = {env_id: env}\n",
        "        else:\n",
        "            reference_envs = {env_id: env, **reference_envs}\n",
        "\n",
        "        plot_simulation_summary(reference_envs)\n",
        "\n",
        "        # plot actions\n",
        "        plot_actions(actions_list, f'{env_id} Actions')\n",
        "\n",
        "        # plot rewards\n",
        "        _, ax = plt.subplots(1, 1, figsize=(5, 2))\n",
        "        ax = plot_rewards(ax, rewards, f'{env_id} Rewards')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    return {\n",
        "        'random_seed': random_seed,\n",
        "        'env': env,\n",
        "        'model': model,\n",
        "        'actions': actions_list,\n",
        "        'rewards': rewards,\n",
        "        'agent_kwargs': agent_kwargs,\n",
        "        'episodes': episodes,\n",
        "        'reward_function': reward_function,\n",
        "        'buildings': buildings,\n",
        "        'simulation_start_time_step': simulation_start_time_step,\n",
        "        'simulation_end_time_step': simulation_end_time_step,\n",
        "        'active_observations': active_observations,\n",
        "        'train_start_timestamp': train_start_timestamp,\n",
        "        'train_end_timestamp': train_end_timestamp,\n",
        "    }"
      ],
      "metadata": {
        "id": "UJc3Rvsf668Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "your_results = train_your_custom_sac(\n",
        "    agent_kwargs=your_agent_kwargs,\n",
        "    episodes=your_episodes,\n",
        "    reward_function=YourCustomReward,\n",
        "    building_count=BUILDING_COUNT,\n",
        "    day_count=DAY_COUNT,\n",
        "    active_observations=your_active_observations,\n",
        "    random_seed=RANDOM_SEED,\n",
        "    reference_envs={\n",
        "        #'RBC': rbc_env,\n",
        "        # 'TQL': tql_env,\n",
        "        #'SAC-1': sac_env,\n",
        "        'SAC-2': sacr_env\n",
        "    },\n",
        "    show_figures=True,\n",
        ")"
      ],
      "metadata": {
        "id": "kFLBpXVA7HQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit\n",
        "\n",
        "You may choose to submit __your results__ to the [scoreboard](https://docs.google.com/spreadsheets/d/1wI1mz7fFiNNc1eZvZfKu_Id23y3QAzL_joVmiqUHm2U/edit?resourcekey#gid=939604299). To this we will programmatically submit your results to a Google Form that live updates the scoreboard in a Google Sheet.\n",
        "\n",
        "Run the following cell to set the function that helps us with the submission.\n",
        "\n",
        ">  **NOTE**:\n",
        "> You do not need to understand the content of the next code cell where the result submission function is defined."
      ],
      "metadata": {
        "id": "JC5e_3AW8a0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def post_results(tag: str, results: dict) -> Tuple[dict, requests.Response]:\n",
        "    \"\"\"Submit your trained SAC model results to public scoreboard.\n",
        "\n",
        "    Submits trained SAC model results to a Google Form and results\n",
        "    are displayed and ranked in Google Sheets.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tag: str\n",
        "        A name to use to identify submitted results in scoreboard.\n",
        "        Avoid including personal identifiers in the tag.\n",
        "    results: dict\n",
        "        Mapping of results from your simulation. It is the variable returned\n",
        "        by the :code:`train_your_custom_sac` function.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    payload: dict\n",
        "        Submitted results.\n",
        "    response: requests.Response\n",
        "        Form post request response.\n",
        "    \"\"\"\n",
        "\n",
        "    # submission for ID\n",
        "    form_id = '1FAIpQLSc69VR3t5z7ag6ydvv11mDpdBS8ruhz4yBfWD_81IUZ2IYtEw'\n",
        "\n",
        "    # url to get and fill the form\n",
        "    get_url = f'https://docs.google.com/forms/d/e/{form_id}/viewform?usp=sf_link'\n",
        "\n",
        "    # url to submit the form\n",
        "    post_url = f'https://docs.google.com/forms/u/1/d/e/{form_id}/formResponse'\n",
        "\n",
        "    # get KPIs\n",
        "    kpis = get_kpis(results['env']).pivot(\n",
        "        index='kpi', columns='name', values='value'\n",
        "    ).to_dict()\n",
        "    kpis = {k: {\n",
        "        k_: float(v_) for k_, v_ in v.items() if not math.isnan(v_)\n",
        "    } for k, v in kpis.items()}\n",
        "\n",
        "    # set payload\n",
        "    datetime_fmt = '%Y-%d-%m %H:%M:%S'\n",
        "    buildings = [int(b.split('_')[-1]) for b in results['buildings']]\n",
        "    buildings = sorted(buildings)\n",
        "    buildings = ', '.join([str(b) for b in buildings])\n",
        "    payload = {\n",
        "        'uid': uuid.uuid4().hex,\n",
        "        'create_timestamp': datetime.utcnow().strftime(datetime_fmt),\n",
        "        'train_start_timestamp': results['train_start_timestamp'].strftime(datetime_fmt),\n",
        "        'train_end_timestamp': results['train_end_timestamp'].strftime(datetime_fmt),\n",
        "        'tag': '' if tag is None else tag,\n",
        "        'random_seed': results['random_seed'],\n",
        "        'buildings': buildings,\n",
        "        'simulation_start_time_step': int(results['simulation_start_time_step']),\n",
        "        'simulation_end_time_step': int(results['simulation_end_time_step']),\n",
        "        'episodes': results['episodes'],\n",
        "        'active_observations': ', '.join(sorted(results['active_observations'])),\n",
        "        'agent_name': str(results['model'].__class__),\n",
        "        'agent_kwargs': results['agent_kwargs'],\n",
        "        'reward_function_calculate': inspect.getsource(results['reward_function'].calculate),\n",
        "        'kpis': kpis,\n",
        "        'district_electricity_consumption': kpis['District']['electricity_consumption'],\n",
        "        'district_cost': kpis['District']['cost'],\n",
        "        'district_carbon_emissions': kpis['District']['carbon_emissions'],\n",
        "        'district_ramping': kpis['District']['ramping'],\n",
        "        'district_average_daily_peak': kpis['District']['average_daily_peak'],\n",
        "        'district_load_factor': kpis['District']['1 - load_factor'],\n",
        "    }\n",
        "\n",
        "    # get form question IDs\n",
        "    response = requests.get(get_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    pattern = re.compile('var FB_PUBLIC_LOAD_DATA_ = (.*?);')\n",
        "    string = soup.findAll(\n",
        "        'script', string=pattern\n",
        "    )[0].string.split(' = ')[-1][:-1]\n",
        "    questions = json.loads(string)[1][1]\n",
        "    questions = {q[1]: q[4][0][0] for q in questions}\n",
        "\n",
        "    # set form question answers\n",
        "    payload = {k: json.dumps(payload[k]) for k, v in questions.items()}\n",
        "    parsed_payload = {f'entry.{questions[k]}': v for k, v in payload.items()}\n",
        "\n",
        "    # submit form\n",
        "    response = requests.post(post_url, data=parsed_payload)\n",
        "\n",
        "    return payload, response"
      ],
      "metadata": {
        "id": "-5xzZ4nt8bRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, run the following cell to set up the submission interface.\n",
        "\n",
        ">  **NOTE**:\n",
        "> You do not need to understand the content of the next code cell where the result submission user interface is defined."
      ],
      "metadata": {
        "id": "ljADPiVk8j1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instructions\n",
        "instructions = \"\"\"\n",
        "<h1>Submit your Results</h1>\n",
        "<p>Use this interactive widget to submit the results of your tuned SAC\n",
        "agent!</p>\n",
        "\n",
        "<p style=\"color:yellow\"><strong>NOTE:</strong> The scoreboard\n",
        "is merely an informational tool. Please, we urge participants\n",
        "to adhere to fair use practices including but not limited to:\n",
        "\n",
        "<ul style=\"color:yellow\">\n",
        "    <li>Do not spam the scoreboard.</li>\n",
        "    <li>Make only one submission for every custom agent\n",
        "    and environment set up.</li>\n",
        "    <li>Do not make alterations to the\n",
        "    <code>post_results</code> function.</li>\n",
        "</ul>\n",
        "\n",
        "</p>\n",
        "\n",
        "<p>Your results are displayed in the\n",
        "<a href=\"https://docs.google.com/spreadsheets\n",
        "/d/1wI1mz7fFiNNc1eZvZfKu_Id23y3QAzL_joVmiqUHm2U/\n",
        "edit?resourcekey#gid=939604299\" target=\"_blank\">scoreboard</a>.</p>\n",
        "\n",
        "\n",
        "<p><strong>Provide a tag (avoid personal identifiers)\n",
        "for your submission and hit the <strong>Submit</strong> button:</strong></p>\n",
        "\"\"\"\n",
        "instructions_html_ui = HTML(value=instructions, placeholder='Instructions')\n",
        "\n",
        "\n",
        "# tag text input\n",
        "tag_text_ui = Text(\n",
        "    value='',\n",
        "    placeholder='Provide a submission tag',\n",
        "    description='Tag:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# submit button\n",
        "submit_button_ui = Button(\n",
        "    description='Submit',\n",
        "    disabled=True,\n",
        "    button_style='success',\n",
        "    tooltip='Submit your Results',\n",
        "    icon='check'\n",
        ")\n",
        "interactions_ui = HBox([tag_text_ui, submit_button_ui])\n",
        "\n",
        "# post-submission html\n",
        "post_submission_html_ui = HTML(value='', placeholder='Post submission report')\n",
        "\n",
        "def on_tag_value_change(change):\n",
        "    \"\"\"Activate/deactivate submit button based on tag value.\"\"\"\n",
        "\n",
        "    value = tag_text_ui.value.strip(' ')\n",
        "\n",
        "    if len(value) > 0:\n",
        "        submit_button_ui.disabled = False\n",
        "    else:\n",
        "        submit_button_ui.disabled = True\n",
        "\n",
        "def on_submit_button_ui_clicked(b):\n",
        "    \"\"\"Submit your results when submit button is clicked.\"\"\"\n",
        "\n",
        "    # set UI pre-submission states\n",
        "    tag_text_ui.disabled = True\n",
        "    submit_button_ui.disabled = True\n",
        "    current_submit_button_description = submit_button_ui.description\n",
        "    submit_button_ui.description = 'Submitting ...'\n",
        "    tag = tag_text_ui.value.strip()\n",
        "    post_submission_html_ui.value = ''\n",
        "\n",
        "    # make submission\n",
        "    payload, response = post_results(tag, your_results)\n",
        "\n",
        "    # confirm successful submission\n",
        "    try:\n",
        "        assert response.status_code == 200\n",
        "        assert 'Your response has been recorded' in response.text\n",
        "        post_submission_html = f\"\"\"\n",
        "        <p style=\"color:green\">Your last submission\n",
        "        on \"{payload['create_timestamp'].strip('\"')} UTC\"\n",
        "        with tag: {payload['tag']}\n",
        "        and unique ID: {payload['uid']}\n",
        "        was successful!</p>\n",
        "        \"\"\"\n",
        "\n",
        "    except AssertionError:\n",
        "        post_submission_html = f\"\"\"\n",
        "        <p style=\"color:red\">Your last submission\n",
        "        on \"{payload['create_timestamp'].strip('\"')} UTC\"\n",
        "        with tag: {payload['tag']}\n",
        "        was unsuccessful!</p>\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    # set UI post-submission states\n",
        "    submit_button_ui.description = current_submit_button_description\n",
        "    tag_text_ui.value = ''\n",
        "    tag_text_ui.disabled = False\n",
        "    submit_button_ui.disabled = False\n",
        "    post_submission_html_ui.value = post_submission_html\n",
        "\n",
        "\n",
        "# callbacks\n",
        "tag_text_ui.observe(on_tag_value_change, names='value')\n",
        "submit_button_ui.on_click(on_submit_button_ui_clicked)\n",
        "\n",
        "# show UI\n",
        "ui = VBox([instructions_html_ui, interactions_ui, post_submission_html_ui])\n",
        "display(ui)"
      ],
      "metadata": {
        "id": "lqSZRoZ48lJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkmytKNU_Z2"
      },
      "source": [
        "# Next Steps\n",
        "---\n",
        "\n",
        "Now that you are a _CityLearner_, here are some next steps and ideas (asides the awesome ideas you probably already have of course ):\n",
        "\n",
        "- Rerun the entire tutorial with a new [RANDOM_SEED](#scrollTo=vfnO0QBszXcS&line=1&uniqifier=1), [number of buildings](#scrollTo=6C6S46xmz50t&line=2&uniqifier=1) (between 1 - 15), [number of days](#scrollTo=6C6S46xmz50t&line=5&uniqifier=1) (1 - 365) and/or [observations](#scrollTo=6C6S46xmz50t&line=8&uniqifier=1). Remember to [set the number of discretization bins](#scrollTo=_6HotiSW4Pe8&line=2&uniqifier=1) for Tabular Q-Learning if you use other observations in your simulations.\n",
        "- How does the Tabular Q-Learning agent perform with a different set of hyperparameters and/or active observations?\n",
        "- How well does the Tabular Q-Learning learn if we use the custom reward function we defined? Are there any improvements compared to the original reward function?\n",
        "- Try to train the SAC agent on all the buildings and the full one-year period in the `citylearn_challenge_2022_phase_all` dataset.\n",
        "- Can you still improve some KPIs without self-generation in the buildings i.e. no photovoltaic (PV) system?\n",
        "- In our hand-on experiments here, we trained and tested on the same days. In reality, when an RL agent is deployed, it may experience states and state transitions that were not seen during training. Try to evaluate your trained agent on a different sequence of days and see if your trained agent generalizes well.\n",
        "- Try out the other datasets in CityLearn.\n",
        "- Check out [The CityLearn Challenge 2022](https://www.aicrowd.com/challenges/neurips-2022-citylearn-challenge).\n",
        "- Bring your own dataset to CityLearn!\n",
        "- \\<Insert __YOUR__ ideas \\>\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/3ohs86vZAWiJXWvQI0/giphy.gif\" height=200></img>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "examples_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aef885a76ce31739e452d1e6967b400907b14827afd25732d0e38ec88d4e0d05"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}